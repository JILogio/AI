{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "questions_and_answers_df = pd.read_csv('questions_and_answers_V2.csv')\n",
    "interactions_df = pd.read_csv('interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento y Entrenamiento de Modelos\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X = questions_and_answers_df['question']\n",
    "y = questions_and_answers_df['answer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizar las preguntas\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelos\n",
    "nb_predictions = nb_model.predict(X_test_vectorized)\n",
    "svm_predictions = svm_model.predict(X_test_vectorized)\n",
    "\n",
    "nb_classification_report = classification_report(y_test, nb_predictions, zero_division=0)\n",
    "svm_classification_report = classification_report(y_test, svm_predictions, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(nb_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM Classification Report:\")\n",
    "print(svm_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, nb_predictions, 'Matriz de Confusión - Naive Bayes')\n",
    "plot_confusion_matrix(y_test, svm_predictions, 'Matriz de Confusión - SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses_to_csv(interactions_df, nb_model, svm_model, vectorizer, output_file):\n",
    "    comparisons = []\n",
    "    for index, row in interactions_df.iterrows():\n",
    "        user_question = row['User']\n",
    "        true_response = row['Bot']\n",
    "        user_question_vectorized = vectorizer.transform([user_question])\n",
    "        nb_response = nb_model.predict(user_question_vectorized)[0]\n",
    "        svm_response = svm_model.predict(user_question_vectorized)[0]\n",
    "        comparisons.append({\n",
    "            'Interaction': index + 1,\n",
    "            'User': user_question,\n",
    "            'True Response': true_response,\n",
    "            'Naive Bayes Response': nb_response,\n",
    "            'SVM Response': svm_response\n",
    "        })\n",
    "    \n",
    "    keys = comparisons[0].keys()\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as output_csv:\n",
    "        dict_writer = csv.DictWriter(output_csv, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(comparisons)\n",
    "\n",
    "# Generar y guardar las respuestas comparativas\n",
    "output_file = 'comparative_responses.csv'\n",
    "compare_responses_to_csv(interactions_df, nb_model, svm_model, vectorizer, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos del archivo CSV comparativo\n",
    "comparative_responses_df = pd.read_csv('comparative_responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de barras para comparar la frecuencia de las respuestas de los modelos con las respuestas verdaderas\n",
    "def plot_response_frequencies(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(x='True Response', data=df, color='blue', label='True Response')\n",
    "    sns.countplot(x='Naive Bayes Response', data=df, color='red', label='Naive Bayes Response')\n",
    "    sns.countplot(x='SVM Response', data=df, color='green', label='SVM Response')\n",
    "    plt.title('Frecuencia de Respuestas')\n",
    "    plt.xlabel('Respuestas')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "plot_response_frequencies(comparative_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión para visualizar las predicciones correctas e incorrectas de Naive Bayes\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(comparative_responses_df['True Response'], comparative_responses_df['Naive Bayes Response'], 'Matriz de Confusión - Naive Bayes')\n",
    "plot_confusion_matrix(comparative_responses_df['True Response'], comparative_responses_df['SVM Response'], 'Matriz de Confusión - SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de dispersión para comparar las respuestas de los modelos y las respuestas verdaderas\n",
    "def plot_scatter_responses(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(x='True Response', y='Naive Bayes Response', data=df, label='Naive Bayes Response', color='red')\n",
    "    sns.scatterplot(x='True Response', y='SVM Response', data=df, label='SVM Response', color='green')\n",
    "    plt.title('Comparación de Respuestas')\n",
    "    plt.xlabel('True Response')\n",
    "    plt.ylabel('Model Response')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter_responses(comparative_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de calor para visualizar la correlación entre las respuestas de los modelos y las respuestas verdaderas\n",
    "def plot_heatmap_responses(df):\n",
    "    correlation_matrix = df[['True Response', 'Naive Bayes Response', 'SVM Response']].apply(lambda x: pd.factorize(x)[0]).corr()\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlación entre Respuestas')\n",
    "    plt.show()\n",
    "\n",
    "plot_heatmap_responses(comparative_responses_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
